kesee,kappa2,delta_s,beta_true_gen="t3",
N_rep=50,M_div_p=20,p_seq=c(100 , 400 ,1600)){
three_xi_hat<-rep(0,3)
betahat_obs_list<-list()
set.seed(rep_i+100) # for observed data beta
beta_true_large=generate_beta(p_seq[3],kappa1,beta_true_gen)
set.seed(rep_i+200) # for observed data X
X_large=matrix(rnorm(p_seq[3]^2*delta , mean = 0, sd = 1), nc = p_seq[3])
# set.seed(rep_i+300) # for source data beta and X
# betas_large=kesee*kappa2/kappa1*beta_true_large+lambda*generate_beta(p_seq[3],kappa1=1,beta_true_gen)
# X_large=matrix(rnorm(p_seq[3]^2*delta_s , mean = 0, sd = 1), nc = p_seq[3]) # make sure generate different data
set.seed(rep_i+400) # for synthetic data
Xstar_large=matrix(rnorm(p_seq[3]^2*M_div_p , mean = 0, sd = 1), nc = p_seq[3])
for(pindex in 1:length(p_seq)){
set.seed(rep_i+1000*pindex)
p=p_seq[pindex]
n=p*delta
M=M_div_p*p
beta_true=beta_true_large[1:p]/sqrt(p)
X = X_large[1:n,1:p]
Y = rbinom(n, 1, 1 / (1 + exp(-X %*% beta_true)))
Xstar = Xstar_large[1:M,1:p]
beta0 = rep(0, p)
Ystar = rbinom(M, 1, 1 / (1 + exp(-Xstar %*% beta0)))
#Ystar=Ystar_large[1:M]
fit_cat_tau_0=glmnet(rbind(X,Xstar),c(Y,Ystar),weights =c(rep(1,n),rep(tau_0*n/M,M)) ,
family = "binomial",alpha=0,lambda = 0,intercept = FALSE,standardize = FALSE)
betahat_tau0=as.numeric(fit_cat_tau_0$beta)
betahat_obs_list[[pindex]]=betahat_tau0
}
betahat_source_list<-list()
set.seed(rep_i+100) # for observed data beta
beta_true_large=generate_beta(p_seq[3],kappa1,beta_true_gen)
# set.seed(rep_i+200) # for observed data X
# X_large=matrix(rnorm(p_seq[3]^2*delta , mean = 0, sd = 1), nc = p_seq[3])
set.seed(rep_i+300) # for source data beta and X
lambda=kappa2*(sqrt(1-kesee^2))
betas_large=kesee*kappa2/kappa1*beta_true_large+lambda*generate_beta(p_seq[3],kappa1=1,beta_true_gen)
X_large=matrix(rnorm(p_seq[3]^2*delta_s , mean = 0, sd = 1), nc = p_seq[3]) # make sure generate different data
set.seed(rep_i+400) # for synthetic data
Xstar_large=matrix(rnorm(p_seq[3]^2*M_div_p , mean = 0, sd = 1), nc = p_seq[3])
for(pindex in 1:length(p_seq)){
set.seed(rep_i+1000*pindex)
p=p_seq[pindex]
n=p*delta_s
M=M_div_p*p
betas=betas_large[1:p]/sqrt(p)
X = X_large[1:n,1:p]
Y = rbinom(n, 1, 1 / (1 + exp(-X %*% betas)))
Xstar = Xstar_large[1:M,1:p]
beta0 = rep(0, p)
Ystar = rbinom(M, 1, 1 / (1 + exp(-Xstar %*% beta0)))
fit_cat_tau_0=glmnet(rbind(X,Xstar),c(Y,Ystar),weights =c(rep(1,n),rep(tau_0*n/M,M)) ,
family = "binomial",alpha=0,lambda = 0,intercept = FALSE,standardize = FALSE)
betahat_tau0=as.numeric(fit_cat_tau_0$beta)
betahat_source_list[[pindex]]=betahat_tau0
}
load(paste0("result_matrix_kappa2_",
kappa1,"_tau_0_",
tau_0,"_kesee_",kesee,"_kappa2_",
kappa2,"_delta_s_",delta_s,"_beta_true_gen_",
beta_true_gen,".RData")) # est_kappa2_matrix
kappa2_three=est_kappa2_matrix[rep_i,]
load(paste0("result_matrix_kappa1_",kappa1,
"_delta_",delta,"_tau_0_",
tau_0,"_beta_true_gen_",beta_true_gen,".RData")) #est_kappa1_matrix
kappa1_three=est_kappa1_matrix[rep_i,]
load(paste0("TheorySolution_non_infor_syn_data_tau_0_0.25_delta_",delta,".RData"))
TheorySolution1=TheorySolution
load(paste0("TheorySolution_non_infor_syn_data_tau_0_0.25_delta_",delta_s,".RData"))
TheorySolution2=TheorySolution
for(pindex in 1:length(p_seq)){
alpha1hat=return_alpha_given_kappa(kappa1_three[pindex],TheorySolution1)
alpha2hat=return_alpha_given_kappa(kappa2_three[pindex],TheorySolution2)
kappa1hat=kappa1_three[pindex]
kappa2hat=kappa2_three[pindex]
three_xi_hat[pindex]=sum(betahat_obs_list[[pindex]]*betahat_source_list[[pindex]])/alpha1hat/alpha2hat/kappa1hat/kappa2hat
}
return(three_xi_hat)
}
return_one_time_xi(rep_i=1,kappa1=1,kappa2=1,tau_0=0.25,kesee=0.5,delta=2,delta_s=4)
return_one_time_xi(rep_i=1,kappa1=1,kappa2=1,tau_0=0.25,kesee=0.5,delta=2,delta_s=10)
load("~/Library/CloudStorage/OneDrive-NationalUniversityofSingapore/CGMT_cat/numerical_study/estimation_of_similarity/est_xi/error_matrix_kesee_hat_kappa1_1_delta_2_tau_0_0.25_kesee_0.9_kappa2_2_delta_s_4_beta_true_gen_t3.RData")
View(error_relative_matrix)
apply(error_relative_matrix,2,mean)
apply(error_relative_matrix,2,sd)
load("~/Library/CloudStorage/OneDrive-NationalUniversityofSingapore/CGMT_cat/numerical_study/estimation_of_similarity/est_xi/error_matrix_kesee_hat_kappa1_1_delta_4_tau_0_0.25_kesee_0.5_kappa2_2_delta_s_10_beta_true_gen_t3.RData")
apply(error_relative_matrix,2,mean)
apply(error_relative_matrix,2,sd)
load("~/Library/CloudStorage/OneDrive-NationalUniversityofSingapore/CGMT_cat/numerical_study/estimation_of_similarity/est_xi/error_matrix_kesee_hat_kappa1_1_delta_2_tau_0_0.25_kesee_0.9_kappa2_2_delta_s_10_beta_true_gen_t3.RData")
View(error_relative_matrix)
# look at result:
tau_0=1/4
for(kappa1 in c(1,2)){
for(delta in c(2,4)){
for(kappa2 in c(1,2)){
for(delta_s in c(4,10)){
for(kesee in c(0.5,0.9)){
load(paste0("error_matrix_kesee_hat_kappa1_",
kappa1,"_delta_",delta,"_tau_0_",
tau_0,"_kesee_",kesee,"_kappa2_",
kappa2,"_delta_s_",delta_s,"_beta_true_gen_",
beta_true_gen,".RData"))
print_matrix=matrix(0,nc=3,nr=2)
print_matrix[1,]=apply(error_relative_matrix,2,mean)
print_matrix[2,]=apply(error_relative_matrix,2,sd)
colnames(print_matrix)=c("p=100","p=400","p=1600")
rownames(print_matrix)=c("mean","sd")
# print current setting
print(paste0("kappa1=",kappa1,"delta=",delta,"kappa2=",kappa2,"delta_s=",delta_s,"kesee=",kesee))
print(print_matrix)
}
}
}
}
}
beta_true_gen="t3"
for(kappa1 in c(1,2)){
for(delta in c(2,4)){
for(kappa2 in c(1,2)){
for(delta_s in c(4,10)){
for(kesee in c(0.5,0.9)){
load(paste0("error_matrix_kesee_hat_kappa1_",
kappa1,"_delta_",delta,"_tau_0_",
tau_0,"_kesee_",kesee,"_kappa2_",
kappa2,"_delta_s_",delta_s,"_beta_true_gen_",
beta_true_gen,".RData"))
print_matrix=matrix(0,nc=3,nr=2)
print_matrix[1,]=apply(error_relative_matrix,2,mean)
print_matrix[2,]=apply(error_relative_matrix,2,sd)
colnames(print_matrix)=c("p=100","p=400","p=1600")
rownames(print_matrix)=c("mean","sd")
# print current setting
print(paste0("kappa1=",kappa1,"delta=",delta,"kappa2=",kappa2,"delta_s=",delta_s,"kesee=",kesee))
print(print_matrix)
}
}
}
}
}
setwd("~/Library/CloudStorage/OneDrive-NationalUniversityofSingapore/CGMT_cat/numerical_study/estimation_of_similarity/est_eta_square_norm")
# look at result:
tau_0=1/4
beta_true_gen="t3"
for(kappa1 in c(1,2)){
for(delta in c(2,4)){
for(kappa2 in c(1,2)){
for(delta_s in c(4,10)){
for(kesee in c(0.5,0.9)){
load(paste0("error_matrix_kesee_hat_kappa1_",
kappa1,"_delta_",delta,"_tau_0_",
tau_0,"_kesee_",kesee,"_kappa2_",
kappa2,"_delta_s_",delta_s,"_beta_true_gen_",
beta_true_gen,".RData"))
print_matrix=matrix(0,nc=3,nr=2)
print_matrix[1,]=apply(error_relative_matrix,2,mean)
print_matrix[2,]=apply(error_relative_matrix,2,sd)
colnames(print_matrix)=c("p=100","p=400","p=1600")
rownames(print_matrix)=c("mean","sd")
# print current setting
print(paste0("kappa1=",kappa1,"delta=",delta,"kappa2=",kappa2,"delta_s=",delta_s,"kesee=",kesee))
print(print_matrix)
}
}
}
}
}
tau_0=1/4
beta_true_gen="t3"
for(kappa1 in c(1)){
for(delta in c(2,4)){
for(kappa2 in c(1)){
for(delta_s in c(4,10)){
for(kesee in c(0.9)){
load(paste0("error_matrix_kesee_hat_kappa1_",
kappa1,"_delta_",delta,"_tau_0_",
tau_0,"_kesee_",kesee,"_kappa2_",
kappa2,"_delta_s_",delta_s,"_beta_true_gen_",
beta_true_gen,".RData"))
print_matrix=matrix(0,nc=3,nr=2)
error_relative_matrix=error_relative_matrix
print_matrix[1,]=apply(error_relative_matrix,2,mean)
print_matrix[2,]=apply(error_relative_matrix,2,sd)
print_matrix=round(print_matrix,3)
colnames(print_matrix)=c("p=100","p=400","p=1600")
rownames(print_matrix)=c("mean","sd")
# print current setting
print(paste0("kappa1=",kappa1,"delta=",delta,"kappa2=",kappa2,"delta_s=",delta_s,"kesee=",kesee))
print(print_matrix)
}
}
}
}
}
setwd("~/Library/CloudStorage/OneDrive-NationalUniversityofSingapore/CGMT_cat/numerical_study/application_theory_procedure/p400_different_betahat_compare/with_sourcedata")
setwd("~/Library/CloudStorage/OneDrive-NationalUniversityofSingapore/CGMT_cat/numerical_study/application_theory_procedure/p400_different_betahat_compare/only_targetdata")
load("~/Library/CloudStorage/OneDrive-NationalUniversityofSingapore/CGMT_cat/numerical_study/case_non_infor_syn_data/TheorySolution_non_infor_syn_data_delta_kappa1_0.5_delta_2.RData")
View(TheorySolution)
kappa1=1
delta=2
load(paste0("result_list_solution_kappahat_p400_kappa1_",kappa1,
"_delta_",delta,".RData"))
View(result_list_solution_kappahat_p400)
result_list_solution_kappahat_p400[[1]]
load(paste0("result_matrix_kappa1_",kappa1,
"_delta_",delta,"_tau_0_",
1/4,"_beta_true_gen_","t3",".RData"))
kappa1_hat=est_kappa1_matrix[,2]
kappa1_hat_seq=est_kappa1_matrix[,2]
load("~/Library/CloudStorage/OneDrive-NationalUniversityofSingapore/CGMT_cat/numerical_study/application_theory_procedure/p400_different_betahat_compare/only_targetdata/TheorySolution_non_infor_syn_data_delta_kappa1_1_delta_2.RData")
load(paste0("TheorySolution_non_infor_syn_data_delta_kappa1_",kappa1,"_delta_",delta,".RData"))
# compute betahat for 50 replications, later can be used to compute mse and pred deviance
# four settings: kappa1={1,2},delta={2,4}
library(glmnet)
library(parallel)
numCores=min(50,detectCores())
library(Rcpp)
library(RcppEigen)
options(rcpp.warnNoExports = FALSE)
sourceCpp("estimate_VE_Eigencpp.cpp")
loocv_best_tau<-function(X,Y,Xstar,Ystar,tau_0_seq){
ve_error=rep(0,length(tau_0_seq))
for(tau_0_index in 1:length(tau_0_seq)){
tau_0=tau_0_seq[tau_0_index]
fit_cat_tau_0=glmnet(rbind(X,Xstar),c(Y,Ystar),weights =c(rep(1,n),rep(tau_0*n/M,M)) ,
family = "binomial",alpha=0,lambda = 0,intercept = FALSE,standardize = FALSE)
betahat_tau0=as.numeric(fit_cat_tau_0$beta)
ve_error[tau_0_index]=estimate_VELOOCV_cpp(X,Y,Xstar,Ystar,tau_0,betahat_tau0)
}
return(tau_0_seq[which.min(ve_error)])
}
# this function will save a list with length N_rep, each element is a vector of betahat
betahat_LOOCV_non_informative_syn_p400<-function(kappa1,delta,beta_true_gen="t3",N_rep=50,M_div_p=20,p_seq=c(100 , 400 ,1600)){
repeat_function_for_betahat<-function(rep_i){
set.seed(rep_i+100) # for observed data beta
beta_true_large=generate_beta(p_seq[3],kappa1,beta_true_gen)
set.seed(rep_i+200) # for observed data X
X_large=matrix(rnorm(p_seq[3]^2*delta , mean = 0, sd = 1), nc = p_seq[3])
# set.seed(rep_i+300) # for source data beta and X
# betas_large=kesee*kappa2/kappa1*beta_true_large+lambda*generate_beta(p_seq[3],kappa1=1,beta_true_gen)
# X_large=matrix(rnorm(p_seq[3]^2*delta_s , mean = 0, sd = 1), nc = p_seq[3]) # make sure generate different data
set.seed(rep_i+400) # for synthetic data
Xstar_large=matrix(rnorm(p_seq[3]^2*M_div_p , mean = 0, sd = 1), nc = p_seq[3])
# only for p400
pindex=2
set.seed(rep_i+1000*pindex)
p=p_seq[pindex]
n=p*delta
M=M_div_p*p
beta_true=beta_true_large[1:p]/sqrt(p)
X = X_large[1:n,1:p]
Y = rbinom(n, 1, 1 / (1 + exp(-X %*% beta_true)))
Xstar = Xstar_large[1:M,1:p]
beta0 = rep(0, p)
Ystar = rbinom(M, 1, 1 / (1 + exp(-Xstar %*% beta0)))
best_tau_0<-loocv_best_tau(X,Y,Xstar,Ystar,tau_0_seq)
fit_cat_besttau_0_loocv=glmnet(rbind(X,Xstar),c(Y,Ystar),weights =c(rep(1,n),rep(best_tau_0*n/M,M)) ,
family = "binomial",alpha=0,lambda = 0,intercept = FALSE,standardize = FALSE)
return(c(best_tau_0,as.numeric(fit_cat_besttau_0_loocv$beta))) # first entries is tau_0_best
}
parallel_betahatloocv_list=mclapply(1:N_rep,repeat_function_for_betahat,mc.cores=numCores)
save(parallel_betahatloocv_list,file=paste0("parallel_betahatloocv_list_non_informative_syn_p400_kappa1_",kappa1,"_delta_",delta,".RData"))
}
betahat_LOOCV_non_informative_syn_p400(kappa1=1,delta=4)
kappa1=1
delta=4
rep_i=1
beta_true_gen="t3"
N_rep=50
p_seq=c(100 , 400 ,1600)
set.seed(rep_i+100) # for observed data beta
beta_true_large=generate_beta(p_seq[3],kappa1,beta_true_gen)
loocv_best_tau<-function(X,Y,Xstar,Ystar,tau_0_seq){
ve_error=rep(0,length(tau_0_seq))
for(tau_0_index in 1:length(tau_0_seq)){
tau_0=tau_0_seq[tau_0_index]
fit_cat_tau_0=glmnet(rbind(X,Xstar),c(Y,Ystar),weights =c(rep(1,n),rep(tau_0*n/M,M)) ,
family = "binomial",alpha=0,lambda = 0,intercept = FALSE,standardize = FALSE)
betahat_tau0=as.numeric(fit_cat_tau_0$beta)
ve_error[tau_0_index]=estimate_VELOOCV_cpp(X,Y,Xstar,Ystar,tau_0,betahat_tau0)
}
return(tau_0_seq[which.min(ve_error)])
}
tau_0_seq=seq(0.1,2,0.1)
generate_beta<-function(p,kappa1,beta_true_gen="normal"){
if(beta_true_gen=="normal"){
return(rnorm(p,sd=kappa1))
}
if(beta_true_gen=="uniform"){
return(runif(p,min=-1,max=1)*kappa1*sqrt(3))
}
if(beta_true_gen=="t3"){
return(rt(p,df=3)*kappa1/sqrt(3))
}
if(beta_true_gen=="halfsparse"){
ind <- sample(c(TRUE, FALSE), p, replace = TRUE)
v=rnorm(p,sd=kappa1*sqrt(2))
v[ind]=0
return(v)
}
}
set.seed(rep_i+100) # for observed data beta
beta_true_large=generate_beta(p_seq[3],kappa1,beta_true_gen)
set.seed(rep_i+200) # for observed data X
X_large=matrix(rnorm(p_seq[3]^2*delta , mean = 0, sd = 1), nc = p_seq[3])
# set.seed(rep_i+300) # for source data beta and X
# betas_large=kesee*kappa2/kappa1*beta_true_large+lambda*generate_beta(p_seq[3],kappa1=1,beta_true_gen)
# X_large=matrix(rnorm(p_seq[3]^2*delta_s , mean = 0, sd = 1), nc = p_seq[3]) # make sure generate different data
set.seed(rep_i+400) # for synthetic data
Xstar_large=matrix(rnorm(p_seq[3]^2*M_div_p , mean = 0, sd = 1), nc = p_seq[3])
M_div_p=20
Xstar_large=matrix(rnorm(p_seq[3]^2*M_div_p , mean = 0, sd = 1), nc = p_seq[3])
# only for p400
pindex=2
set.seed(rep_i+1000*pindex)
p=p_seq[pindex]
n=p*delta
M=M_div_p*p
beta_true=beta_true_large[1:p]/sqrt(p)
X = X_large[1:n,1:p]
Y = rbinom(n, 1, 1 / (1 + exp(-X %*% beta_true)))
Xstar = Xstar_large[1:M,1:p]
beta0 = rep(0, p)
Ystar = rbinom(M, 1, 1 / (1 + exp(-Xstar %*% beta0)))
best_tau_0<-loocv_best_tau(X,Y,Xstar,Ystar,tau_0_seq)
fit_cat_besttau_0_loocv=glmnet(rbind(X,Xstar),c(Y,Ystar),weights =c(rep(1,n),rep(best_tau_0*n/M,M)) ,
family = "binomial",alpha=0,lambda = 0,intercept = FALSE,standardize = FALSE)
c(best_tau_0,as.numeric(fit_cat_besttau_0_loocv$beta))
tau_0_seq=seq(0.1,2,0.1)
generate_beta<-function(p,kappa1,beta_true_gen="normal"){
if(beta_true_gen=="normal"){
return(rnorm(p,sd=kappa1))
}
if(beta_true_gen=="uniform"){
return(runif(p,min=-1,max=1)*kappa1*sqrt(3))
}
if(beta_true_gen=="t3"){
return(rt(p,df=3)*kappa1/sqrt(3))
}
if(beta_true_gen=="halfsparse"){
ind <- sample(c(TRUE, FALSE), p, replace = TRUE)
v=rnorm(p,sd=kappa1*sqrt(2))
v[ind]=0
return(v)
}
}
loocv_best_tau<-function(X,Y,Xstar,Ystar,tau_0_seq){
ve_error=rep(0,length(tau_0_seq))
for(tau_0_index in 1:length(tau_0_seq)){
tau_0=tau_0_seq[tau_0_index]
fit_cat_tau_0=glmnet(rbind(X,Xstar),c(Y,Ystar),weights =c(rep(1,n),rep(tau_0*n/M,M)) ,
family = "binomial",alpha=0,lambda = 0,intercept = FALSE,standardize = FALSE)
betahat_tau0=as.numeric(fit_cat_tau_0$beta)
ve_error[tau_0_index]=estimate_VELOOCV_cpp(X,Y,Xstar,Ystar,tau_0,betahat_tau0)
}
return(tau_0_seq[which.min(ve_error)])
}
# this function will save a list with length N_rep, each element is a vector of betahat
betahat_LOOCV_non_informative_syn_p400<-function(kappa1,delta,beta_true_gen="t3",N_rep=50,M_div_p=20,p_seq=c(100 , 400 ,1600)){
repeat_function_for_betahat<-function(rep_i){
set.seed(rep_i+100) # for observed data beta
beta_true_large=generate_beta(p_seq[3],kappa1,beta_true_gen)
set.seed(rep_i+200) # for observed data X
X_large=matrix(rnorm(p_seq[3]^2*delta , mean = 0, sd = 1), nc = p_seq[3])
# set.seed(rep_i+300) # for source data beta and X
# betas_large=kesee*kappa2/kappa1*beta_true_large+lambda*generate_beta(p_seq[3],kappa1=1,beta_true_gen)
# X_large=matrix(rnorm(p_seq[3]^2*delta_s , mean = 0, sd = 1), nc = p_seq[3]) # make sure generate different data
set.seed(rep_i+400) # for synthetic data
Xstar_large=matrix(rnorm(p_seq[3]^2*M_div_p , mean = 0, sd = 1), nc = p_seq[3])
# only for p400
pindex=2
set.seed(rep_i+1000*pindex)
p=p_seq[pindex]
n=p*delta
M=M_div_p*p
beta_true=beta_true_large[1:p]/sqrt(p)
X = X_large[1:n,1:p]
Y = rbinom(n, 1, 1 / (1 + exp(-X %*% beta_true)))
Xstar = Xstar_large[1:M,1:p]
beta0 = rep(0, p)
Ystar = rbinom(M, 1, 1 / (1 + exp(-Xstar %*% beta0)))
best_tau_0<-loocv_best_tau(X,Y,Xstar,Ystar,tau_0_seq)
fit_cat_besttau_0_loocv=glmnet(rbind(X,Xstar),c(Y,Ystar),weights =c(rep(1,n),rep(best_tau_0*n/M,M)) ,
family = "binomial",alpha=0,lambda = 0,intercept = FALSE,standardize = FALSE)
return(c(best_tau_0,as.numeric(fit_cat_besttau_0_loocv$beta))) # first entries is tau_0_best
}
parallel_betahatloocv_list=mclapply(1:N_rep,repeat_function_for_betahat,mc.cores=numCores)
save(parallel_betahatloocv_list,file=paste0("parallel_betahatloocv_list_non_informative_syn_p400_kappa1_",kappa1,"_delta_",delta,".RData"))
}
for(kappa1 in c(1,2)){
for(delta in c(2,4)){
betahat_LOOCV_non_informative_syn_p400(kappa1,delta)
}
}
repeat_function_for_betahat<-function(rep_i){
set.seed(rep_i+100) # for observed data beta
beta_true_large=generate_beta(p_seq[3],kappa1,beta_true_gen)
set.seed(rep_i+200) # for observed data X
X_large=matrix(rnorm(p_seq[3]^2*delta , mean = 0, sd = 1), nc = p_seq[3])
# set.seed(rep_i+300) # for source data beta and X
# betas_large=kesee*kappa2/kappa1*beta_true_large+lambda*generate_beta(p_seq[3],kappa1=1,beta_true_gen)
# X_large=matrix(rnorm(p_seq[3]^2*delta_s , mean = 0, sd = 1), nc = p_seq[3]) # make sure generate different data
set.seed(rep_i+400) # for synthetic data
Xstar_large=matrix(rnorm(p_seq[3]^2*M_div_p , mean = 0, sd = 1), nc = p_seq[3])
# only for p400
pindex=2
set.seed(rep_i+1000*pindex)
p=p_seq[pindex]
n=p*delta
M=M_div_p*p
beta_true=beta_true_large[1:p]/sqrt(p)
X = X_large[1:n,1:p]
Y = rbinom(n, 1, 1 / (1 + exp(-X %*% beta_true)))
Xstar = Xstar_large[1:M,1:p]
beta0 = rep(0, p)
Ystar = rbinom(M, 1, 1 / (1 + exp(-Xstar %*% beta0)))
best_tau_0<-loocv_best_tau(X,Y,Xstar,Ystar,tau_0_seq)
fit_cat_besttau_0_loocv=glmnet(rbind(X,Xstar),c(Y,Ystar),weights =c(rep(1,n),rep(best_tau_0*n/M,M)) ,
family = "binomial",alpha=0,lambda = 0,intercept = FALSE,standardize = FALSE)
return(c(best_tau_0,as.numeric(fit_cat_besttau_0_loocv$beta))) # first entries is tau_0_best
}
repeat_function_for_betahat(2)
rm(list=ls())
# compute betahat for 50 replications, later can be used to compute mse and pred deviance
# four settings: kappa1={1,2},delta={2,4}
library(glmnet)
library(parallel)
numCores=min(50,detectCores())
library(Rcpp)
library(RcppEigen)
options(rcpp.warnNoExports = FALSE)
sourceCpp("estimate_VE_Eigencpp.cpp")
tau_0_seq=seq(0.1,2,0.1)
generate_beta<-function(p,kappa1,beta_true_gen="normal"){
if(beta_true_gen=="normal"){
return(rnorm(p,sd=kappa1))
}
if(beta_true_gen=="uniform"){
return(runif(p,min=-1,max=1)*kappa1*sqrt(3))
}
if(beta_true_gen=="t3"){
return(rt(p,df=3)*kappa1/sqrt(3))
}
if(beta_true_gen=="halfsparse"){
ind <- sample(c(TRUE, FALSE), p, replace = TRUE)
v=rnorm(p,sd=kappa1*sqrt(2))
v[ind]=0
return(v)
}
}
loocv_best_tau<-function(X,Y,Xstar,Ystar,tau_0_seq){
ve_error=rep(0,length(tau_0_seq))
for(tau_0_index in 1:length(tau_0_seq)){
tau_0=tau_0_seq[tau_0_index]
fit_cat_tau_0=glmnet(rbind(X,Xstar),c(Y,Ystar),weights =c(rep(1,n),rep(tau_0*n/M,M)) ,
family = "binomial",alpha=0,lambda = 0,intercept = FALSE,standardize = FALSE)
betahat_tau0=as.numeric(fit_cat_tau_0$beta)
ve_error[tau_0_index]=estimate_VELOOCV_cpp(X,Y,Xstar,Ystar,tau_0,betahat_tau0)
}
return(tau_0_seq[which.min(ve_error)])
}
kappa1=1
delta=4
beta_true_gen="t3"
M_div_p=20
p_seq=c(100 , 400 ,1600)
repeat_function_for_betahat(2)
repeat_function_for_betahat<-function(rep_i){
set.seed(rep_i+100) # for observed data beta
beta_true_large=generate_beta(p_seq[3],kappa1,beta_true_gen)
set.seed(rep_i+200) # for observed data X
X_large=matrix(rnorm(p_seq[3]^2*delta , mean = 0, sd = 1), nc = p_seq[3])
# set.seed(rep_i+300) # for source data beta and X
# betas_large=kesee*kappa2/kappa1*beta_true_large+lambda*generate_beta(p_seq[3],kappa1=1,beta_true_gen)
# X_large=matrix(rnorm(p_seq[3]^2*delta_s , mean = 0, sd = 1), nc = p_seq[3]) # make sure generate different data
set.seed(rep_i+400) # for synthetic data
Xstar_large=matrix(rnorm(p_seq[3]^2*M_div_p , mean = 0, sd = 1), nc = p_seq[3])
# only for p400
pindex=2
set.seed(rep_i+1000*pindex)
p=p_seq[pindex]
n=p*delta
M=M_div_p*p
beta_true=beta_true_large[1:p]/sqrt(p)
X = X_large[1:n,1:p]
Y = rbinom(n, 1, 1 / (1 + exp(-X %*% beta_true)))
Xstar = Xstar_large[1:M,1:p]
beta0 = rep(0, p)
Ystar = rbinom(M, 1, 1 / (1 + exp(-Xstar %*% beta0)))
best_tau_0<-loocv_best_tau(X,Y,Xstar,Ystar,tau_0_seq)
fit_cat_besttau_0_loocv=glmnet(rbind(X,Xstar),c(Y,Ystar),weights =c(rep(1,n),rep(best_tau_0*n/M,M)) ,
family = "binomial",alpha=0,lambda = 0,intercept = FALSE,standardize = FALSE)
return(c(best_tau_0,as.numeric(fit_cat_besttau_0_loocv$beta))) # first entries is tau_0_best
}
repeat_function_for_betahat(2)
load("~/Library/CloudStorage/OneDrive-NationalUniversityofSingapore/CGMT_cat/numerical_study/application_theory_procedure/p400_different_betahat_compare/only_targetdata/TheorySolution_non_infor_syn_data_delta_kappa1_1_delta_4.RData")
View(TheorySolution)
TheorySolution
load("~/Library/CloudStorage/OneDrive-NationalUniversityofSingapore/CGMT_cat/numerical_study/application_theory_procedure/p400_different_betahat_compare/only_targetdata/appendTheorySolution_non_infor_syn_data_delta_kappa1_1_delta_4.RData")
TheorySolution
load("~/Library/CloudStorage/OneDrive-NationalUniversityofSingapore/CGMT_cat/numerical_study/application_theory_procedure/p400_different_betahat_compare/only_targetdata/appendresult_list_solution_kappahat_p400_kappa1_1_delta_2.RData")
View(result_list_solution_kappahat_p400)
load("~/Library/CloudStorage/OneDrive-NationalUniversityofSingapore/CGMT_cat/numerical_study/application_theory_procedure/p400_different_betahat_compare/only_targetdata/appendresult_list_solution_kappahat_p400_kappa1_1_delta_2.RData")
kappa1=1
delta=2
load(paste0("TheorySolution_non_infor_syn_data_delta_kappa1_",kappa1,"_delta_",delta,".RData"))
Theorysolution_smalltau=TheorySolution
load(paste0("appendTheorySolution_non_infor_syn_data_delta_kappa1_",kappa1,"_delta_",delta,".RData"))
Theorysolution_largetau=TheorySolution
TheorySolution=rbind(Theorysolution_smalltau,Theorysolution_largetau)
load("~/Library/CloudStorage/OneDrive-NationalUniversityofSingapore/CGMT_cat/numerical_study/application_theory_procedure/p400_different_betahat_compare/with_sourcedata/result_list_solution_kappa12keseehat_p400_kappa1_1_delta_2_tau_0_0.25_kesee_0.9_kappa2_1_delta_s_10_beta_true_gen_t3.RData")
load("~/Library/CloudStorage/OneDrive-NationalUniversityofSingapore/CGMT_cat/numerical_study/application_theory_procedure/p400_different_betahat_compare/with_sourcedata/appendresult_list_solution_kappa12keseehat_p400_kappa1_1_delta_2_tau_0_0.25_kesee_0.9_kappa2_1_delta_s_10_beta_true_gen_t3.RData")
